{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "USE with model example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFf9GSS6AKF4"
      },
      "source": [
        "# A notebook by:\n",
        "# Bahram K Baloch\n",
        "## https://www.linkedin.com/in/bahramkbaloch\n",
        "## BahramKBaloch@gmail.com\n",
        "\n",
        "https://github.com/BahramKBaloch/USE-Example/blob/main/README.md\n",
        "\n",
        "This notebook was made by combining multiple resources available online.\n",
        "\n",
        ":: Run is notebook in google-colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IMg_z16l_2Z"
      },
      "source": [
        "# Text Classification\n",
        "\n",
        "In this notebook we will classify movie reviews as being either `positive` or `negative`. We'll use the [IMDB dataset](https://www.tensorflow.org/datasets/catalog/imdb_reviews) that contains the text of 50,000 movie reviews from the [Internet Movie Database](https://www.imdb.com/). These are split into 25,000 reviews for training and 25,000 reviews for testing. The training and testing sets are *balanced*, meaning they contain an equal number of positive and negative reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-B-0zxxtwFQV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aec365bd-611d-4541-e4bf-653abff42a93"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "print(\"\\u2022 Using TensorFlow Version:\", tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "• Using TensorFlow Version: 2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBIRo8Xtl_2h"
      },
      "source": [
        "## Download the IMDB Dataset\n",
        "\n",
        "We will download the [IMDB dataset](https://www.tensorflow.org/datasets/catalog/imdb_reviews) using TensorFlow Datasets. We will use a training set, a validation set, and a test set. Since the IMDB dataset doesn't have a validation split, we will use the first 60\\% of the training set for training, and the last 40\\% of the training set for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfnt5ibsl_2i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9681f113-0c6f-43e5-c64f-98728396caa7"
      },
      "source": [
        "splits = ['train[:60%]', 'train[-40%:]', 'test']\n",
        "\n",
        "splits, info = tfds.load(name=\"imdb_reviews\", with_info=True, split=splits, as_supervised=True)\n",
        "\n",
        "train_data, validation_data, test_data = splits"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset imdb_reviews/plain_text/1.0.0 (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteA2QXR6/imdb_reviews-train.tfrecord\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteA2QXR6/imdb_reviews-test.tfrecord\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset is using deprecated text encoder API which will be removed soon. Please use the plain_text version of the dataset and migrate to `tensorflow_text`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteA2QXR6/imdb_reviews-unsupervised.tfrecord\n",
            "\u001b[1mDataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbbsJKch1lL5"
      },
      "source": [
        "## Explore the Data \n",
        "\n",
        "Let's take a moment to look at the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gh4Taekl_2k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44aedb56-1227-4dbc-da75-78dbb698e6cc"
      },
      "source": [
        "num_train_examples = info.splits['train'].num_examples\n",
        "num_test_examples = info.splits['test'].num_examples\n",
        "num_classes = info.features['label'].num_classes\n",
        "\n",
        "print('The Dataset has a total of:')\n",
        "print('\\u2022 {:,} classes'.format(num_classes))\n",
        "\n",
        "print('\\u2022 {:,} movie reviews for training'.format(num_train_examples))\n",
        "print('\\u2022 {:,} movie reviews for testing'.format(num_test_examples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Dataset has a total of:\n",
            "• 2 classes\n",
            "• 25,000 movie reviews for training\n",
            "• 25,000 movie reviews for testing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIyvvYFF2DXz"
      },
      "source": [
        "The labels are either 0 or 1, where 0 is a negative review, and 1 is a positive review. We will create a list with the corresponding class names, so that we can map labels to class names later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SAGQKTdl_2n"
      },
      "source": [
        "class_names = ['negative', 'positive']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrLs9vQr16JH"
      },
      "source": [
        "Each example consists of a sentence representing the movie review and a corresponding label. The sentence is not preprocessed in any way. Let's take a look at the first example of the training set.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6lqHTTzl_2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb5ed66-6d2e-4f54-e416-06f0bb2e5318"
      },
      "source": [
        "for review, label in train_data.take(1):\n",
        "    review = review.numpy()\n",
        "    label = label.numpy()\n",
        "\n",
        "    print('\\nMovie Review:\\n\\n', review)\n",
        "    print('\\nLabel:', class_names[label])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Movie Review:\n",
            "\n",
            " b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
            "\n",
            "Label: negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tam__wal_2s"
      },
      "source": [
        "## Load USE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbYukNNs2y7H"
      },
      "source": [
        "embedding = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "\n",
        "hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkkv57f5A5w1"
      },
      "source": [
        "raw_text = \"There are films that make careers. For George Romero, it was NIGHT OF THE LIVING DEAD; for Kevin Smith, CLERKS; for Robert Rodriguez, EL MARIACHI. Add to that list Onur Tukel's absolutely amazing DING-A-LING-LESS. Flawless film-making, and as assured and as professional as any of the aforementioned movies. I haven't laughed this hard since I saw THE FULL MONTY. (And, even then, I don't think I laughed quite this hard... So to speak.) Tukel's talent is considerable: DING-A-LING-LESS is so chock full of double entendres that one would have to sit down with a copy of this script and do a line-by-line examination of it to fully appreciate the, uh, breadth and width of it. Every shot is beautifully composed (a clear sign of a sure-handed director), and the performances all around are solid (there's none of the over-the-top scenery chewing one might've expected from a film like this). DING-A-LING-LESS is a film whose time has come.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl11Hha-BBbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c303dc6c-1902-4988-bd38-67ea9982a34e"
      },
      "source": [
        "hub_layer([raw_text])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 512), dtype=float32, numpy=\n",
              "array([[-5.41191967e-03, -2.37394311e-02,  6.49590865e-02,\n",
              "         1.84691008e-02,  7.65666887e-02, -2.27458905e-02,\n",
              "         4.31798697e-02,  4.21065558e-03,  3.77488695e-02,\n",
              "        -3.77925709e-02,  3.71346734e-02, -2.61247549e-02,\n",
              "        -8.68634600e-03,  2.13593747e-02, -8.69560335e-03,\n",
              "        -6.56103939e-02, -3.71810980e-03,  5.92230111e-02,\n",
              "         5.21432050e-02,  4.59606089e-02, -1.56899765e-02,\n",
              "        -8.15043449e-02, -6.40605763e-02, -6.28283024e-02,\n",
              "        -5.55560738e-02,  1.83062386e-02, -3.17220204e-02,\n",
              "        -2.74954140e-02, -7.32726604e-02,  8.15091804e-02,\n",
              "        -1.99652631e-02, -2.34793108e-02, -1.44523103e-02,\n",
              "        -9.80413705e-03, -1.16190626e-04, -3.44093330e-02,\n",
              "         3.68965417e-02,  6.43856823e-02,  2.66543142e-02,\n",
              "        -4.08752635e-02, -1.27727007e-02, -3.23581174e-02,\n",
              "        -8.00806284e-02, -1.09695029e-02, -3.38477874e-03,\n",
              "        -4.55326848e-02, -2.56307870e-02,  5.15219430e-03,\n",
              "        -1.12989480e-02,  5.90574332e-02,  4.29528859e-03,\n",
              "        -7.18135536e-02,  1.70513301e-03,  1.71245076e-02,\n",
              "         3.05885151e-02,  1.59040131e-02, -4.43727374e-02,\n",
              "         3.52307446e-02,  7.25340471e-02, -6.94547817e-02,\n",
              "         8.11437443e-02, -2.97562666e-02, -7.90201798e-02,\n",
              "        -2.85477545e-02, -2.21498925e-02,  6.60799742e-02,\n",
              "        -2.29416881e-02,  2.53961030e-02, -1.27297947e-02,\n",
              "        -3.76622044e-02,  3.43688801e-02,  7.32623190e-02,\n",
              "        -3.07796281e-02,  6.19549640e-02,  4.82611656e-02,\n",
              "        -7.96205252e-02,  2.00666804e-02, -1.19487727e-02,\n",
              "         7.23887756e-02,  4.62463163e-02, -4.65986319e-02,\n",
              "        -6.23090640e-02, -4.19090176e-03,  2.86902674e-02,\n",
              "        -1.03518153e-02, -6.02132566e-02,  2.30200794e-02,\n",
              "        -6.42972160e-03, -7.55199715e-02, -2.57290434e-02,\n",
              "        -3.49676074e-03, -4.24707979e-02,  1.21163437e-02,\n",
              "        -3.85175049e-02,  8.14598128e-02, -3.34874690e-02,\n",
              "        -4.97785360e-02,  2.36288607e-02,  8.13970119e-02,\n",
              "         4.85299304e-02, -4.21850048e-02, -1.08243607e-03,\n",
              "        -5.43455705e-02, -9.01648868e-03, -3.89148705e-02,\n",
              "        -6.58579729e-03, -4.74969745e-02,  5.81037663e-02,\n",
              "        -2.16927342e-02,  6.41216785e-02, -2.44473834e-02,\n",
              "        -9.58564691e-03, -1.35570401e-02,  8.01205356e-03,\n",
              "         1.53879216e-02,  2.59746574e-02,  3.73584256e-02,\n",
              "        -2.64628176e-02,  2.39276979e-02,  4.85303327e-02,\n",
              "        -3.30444649e-02,  3.84264365e-02, -6.20690472e-02,\n",
              "        -7.74877239e-03, -1.80009082e-02, -5.27528897e-02,\n",
              "         1.10598179e-02, -8.15125331e-02,  2.94043869e-02,\n",
              "         6.17254600e-02, -3.60229127e-02,  1.18788984e-02,\n",
              "         2.32342947e-02, -5.26615903e-02,  6.44145012e-02,\n",
              "        -1.81037690e-02,  5.86315691e-02,  3.87758575e-02,\n",
              "        -6.02087267e-02,  4.88674045e-02, -1.40707064e-02,\n",
              "         8.14476386e-02, -3.44237424e-02,  5.52739576e-02,\n",
              "        -2.48439740e-02,  8.42258520e-03,  4.17181812e-02,\n",
              "        -1.59301702e-02, -2.81186716e-04,  1.07402066e-02,\n",
              "        -2.69214064e-02, -5.53141870e-02, -7.73209259e-02,\n",
              "        -5.75770140e-02,  3.74455489e-02,  3.60945091e-02,\n",
              "        -4.59613614e-02,  2.01400928e-02,  5.53718135e-02,\n",
              "        -3.07012592e-02, -2.70621590e-02, -2.40980815e-02,\n",
              "         3.91647294e-02,  6.79519400e-02,  6.78718239e-02,\n",
              "         5.35839349e-02, -3.26753892e-02, -3.30444090e-02,\n",
              "        -2.37672664e-02, -1.37631232e-02,  5.97567260e-02,\n",
              "        -1.21346554e-02,  2.77931262e-02, -1.20507451e-02,\n",
              "        -5.00048846e-02,  2.22747531e-02,  6.43077167e-03,\n",
              "         3.58718894e-02,  5.86924739e-02, -8.07577893e-02,\n",
              "         4.54547703e-02,  7.72980899e-02, -9.78289871e-04,\n",
              "        -5.38261235e-02, -2.37074643e-02,  6.16778918e-02,\n",
              "         5.65696089e-03,  2.22101919e-02,  5.81380539e-02,\n",
              "         6.50475547e-03,  6.34249300e-02,  2.45229192e-02,\n",
              "        -1.72153339e-02, -8.04587603e-02,  2.64991708e-02,\n",
              "        -2.58683767e-02,  2.02668514e-02, -1.97115894e-02,\n",
              "         6.63265679e-03,  2.12594867e-02, -1.66318901e-02,\n",
              "         5.77606931e-02, -7.53521174e-03,  2.44526863e-02,\n",
              "         6.95430934e-02, -5.51974922e-02,  6.55136397e-03,\n",
              "        -5.89749366e-02, -1.76414978e-02,  2.23998725e-02,\n",
              "        -1.65843870e-02,  7.60508180e-02, -8.18540435e-03,\n",
              "         2.05600094e-02, -6.07123785e-02, -1.18398834e-02,\n",
              "        -1.85791831e-02, -2.29874030e-02, -1.94280837e-02,\n",
              "         5.02409115e-02,  4.24310677e-02,  4.18438017e-03,\n",
              "        -6.54883543e-03,  1.06811489e-03, -7.98596367e-02,\n",
              "        -2.73267590e-02, -5.28331511e-02, -4.65824418e-02,\n",
              "         6.13303073e-02, -2.84603760e-02,  4.20241281e-02,\n",
              "        -2.93802880e-02,  4.61389422e-02, -8.15050453e-02,\n",
              "        -4.77049733e-03,  1.16268862e-02,  3.10077276e-02,\n",
              "         1.51108867e-02, -5.56033254e-02,  2.81589180e-02,\n",
              "         3.07202954e-02, -3.50433066e-02,  5.40570021e-02,\n",
              "        -9.35578998e-03,  3.33656222e-02,  8.01697653e-03,\n",
              "        -1.80390496e-02, -6.45561218e-02,  2.56731082e-02,\n",
              "         8.44735838e-03,  5.08406609e-02, -6.30062446e-02,\n",
              "         5.02696522e-02, -6.77378336e-03,  4.21152376e-02,\n",
              "        -8.53164960e-03,  5.46090864e-02,  8.15126300e-02,\n",
              "         5.63071482e-02,  5.76781034e-02,  4.42898907e-02,\n",
              "         4.71834987e-02, -5.31143248e-02, -4.44985880e-03,\n",
              "        -4.04755212e-02,  2.02124473e-02, -4.90391813e-02,\n",
              "         5.60775474e-02,  6.68180212e-02, -2.17778720e-02,\n",
              "         3.22549343e-02,  7.79616833e-02, -5.54820858e-02,\n",
              "        -5.87751083e-02, -4.65297960e-02, -3.44737656e-02,\n",
              "        -6.00387789e-02, -7.09639639e-02,  7.77548030e-02,\n",
              "         8.02513063e-02, -4.08599749e-02,  3.93398814e-02,\n",
              "         4.58479524e-02,  4.59052548e-02, -7.43441703e-03,\n",
              "        -8.15127119e-02,  1.14835305e-02, -2.32980790e-04,\n",
              "         4.42521051e-02,  2.05111876e-02, -6.05771318e-02,\n",
              "         7.91784823e-02,  7.04103857e-02, -2.98605654e-02,\n",
              "         4.24569026e-02,  4.10509631e-02,  6.52892143e-02,\n",
              "        -4.32581939e-02,  9.17125866e-03,  6.27910346e-02,\n",
              "         4.55545820e-02, -4.84366305e-02, -2.28904951e-02,\n",
              "        -1.46982102e-02,  1.97603591e-02,  7.81384669e-03,\n",
              "        -4.18046140e-04,  1.50542455e-02,  3.84986252e-02,\n",
              "         4.28637415e-02,  2.51700468e-02, -2.52485904e-03,\n",
              "        -4.82823402e-02, -5.90869598e-03,  1.05866566e-02,\n",
              "         2.49575973e-02,  2.14170432e-03, -1.15182847e-02,\n",
              "         4.61896807e-02,  7.80805051e-02, -4.35625911e-02,\n",
              "        -1.38174370e-02, -2.13978700e-02, -3.66680175e-02,\n",
              "         3.19001600e-02,  1.05792508e-02,  4.38300148e-02,\n",
              "         4.74289991e-02, -4.89434749e-02, -1.29704773e-02,\n",
              "         2.85163336e-02,  3.65520455e-02,  6.12074733e-02,\n",
              "         1.16450451e-02, -7.85517842e-02, -5.68742529e-02,\n",
              "        -2.53808568e-03, -5.74369617e-02,  4.86755595e-02,\n",
              "         3.99215659e-03,  8.08758214e-02,  6.80277795e-02,\n",
              "         1.39997136e-02,  5.89806214e-02, -3.01579162e-02,\n",
              "        -6.23231530e-02,  3.94553468e-02, -8.01027939e-02,\n",
              "        -3.10147256e-02,  6.06351271e-02, -3.59678967e-03,\n",
              "         1.52503774e-02, -2.67254896e-02, -5.50195947e-02,\n",
              "        -3.75253558e-02, -8.05500299e-02, -8.11566934e-02,\n",
              "        -6.38096407e-02,  5.35244867e-03,  3.75459418e-02,\n",
              "        -4.44624631e-04, -3.58250700e-02,  7.97633827e-02,\n",
              "         4.09084149e-02,  4.88708243e-02, -1.93796027e-02,\n",
              "         6.89162016e-02,  6.07443899e-02,  5.76261878e-02,\n",
              "        -4.53989487e-03, -4.11906186e-03, -2.96533704e-02,\n",
              "        -2.53226049e-02,  4.66519706e-02, -5.34125753e-02,\n",
              "         1.39721874e-02, -7.64963217e-03, -6.55151308e-02,\n",
              "         3.66867334e-02, -7.37579092e-02, -2.37101391e-02,\n",
              "        -4.85158637e-02,  4.09338623e-02,  1.09460447e-02,\n",
              "         6.43833578e-02, -7.27086067e-02,  1.85320713e-02,\n",
              "         4.87446226e-02, -5.99921718e-02, -2.12183874e-02,\n",
              "         6.71748146e-02,  2.39416901e-02,  4.16127369e-02,\n",
              "        -4.37494442e-02,  8.26717727e-03, -1.08714262e-02,\n",
              "        -4.90457416e-02,  3.84317786e-02, -4.58346419e-02,\n",
              "        -7.82446414e-02,  4.08605747e-02, -5.59280440e-02,\n",
              "        -4.87235636e-02, -2.94964612e-02,  8.15126523e-02,\n",
              "         1.39294248e-02,  8.15042332e-02,  1.66386236e-02,\n",
              "         2.00095344e-02,  2.51973495e-02, -2.76334714e-02,\n",
              "         1.57798957e-02,  2.12499890e-02,  2.10788269e-02,\n",
              "         8.00474063e-02, -6.38062283e-02, -6.46452233e-02,\n",
              "        -5.71292341e-02,  3.93425534e-03, -6.55122027e-02,\n",
              "         6.38561845e-02,  4.01078723e-03, -7.37533569e-02,\n",
              "        -4.37694713e-02,  4.74863220e-03,  3.71112637e-02,\n",
              "         2.47427020e-02,  6.92899078e-02, -5.01831360e-02,\n",
              "         8.02932978e-02,  1.16751008e-02,  3.68604995e-02,\n",
              "        -3.39383520e-02,  5.41609004e-02, -5.66561222e-02,\n",
              "        -3.85573655e-02,  2.10468546e-02,  2.57763993e-02,\n",
              "        -2.77235974e-02, -5.80955260e-02, -5.76778166e-02,\n",
              "        -6.29636571e-02,  4.39036414e-02,  2.08086725e-02,\n",
              "         3.90665904e-02,  5.82940355e-02,  2.99591012e-02,\n",
              "         2.16775853e-02, -1.85129363e-02,  2.62186602e-02,\n",
              "        -2.12245213e-05,  3.26269381e-02,  1.05886068e-02,\n",
              "         7.48720914e-02, -1.72080752e-02, -1.71449985e-02,\n",
              "         2.92791016e-02, -3.13865114e-03, -2.91475467e-02,\n",
              "         1.91317126e-02,  3.97829488e-02,  6.45791888e-02,\n",
              "         2.66151894e-02, -8.85322370e-05, -3.67978327e-02,\n",
              "         4.37505580e-02,  3.53349037e-02,  2.19154661e-03,\n",
              "        -4.21592742e-02,  3.59617826e-03,  4.84134480e-02,\n",
              "         2.20624786e-02, -4.16355841e-02, -3.01346220e-02,\n",
              "        -1.78800598e-02,  3.35361585e-02,  3.36215645e-02,\n",
              "        -3.75764035e-02,  7.85428062e-02, -5.62242419e-02,\n",
              "        -1.56435277e-02, -1.63807869e-02,  1.36310533e-02,\n",
              "        -8.00733194e-02, -3.10406764e-03, -5.06638549e-02,\n",
              "         2.87935063e-02,  8.14988986e-02, -2.86345985e-02,\n",
              "         5.01355939e-02,  4.03855741e-02, -7.52174237e-05,\n",
              "        -7.01941624e-02,  4.91629541e-02,  2.97835860e-02,\n",
              "         2.27046441e-02, -6.45373687e-02, -8.93240701e-03,\n",
              "         4.94149514e-02, -4.60169874e-02, -1.90022271e-02,\n",
              "        -7.97833353e-02, -6.16782643e-02, -8.10607970e-02,\n",
              "         2.49357224e-02, -5.03260344e-02, -6.67384341e-02,\n",
              "         8.07215944e-02,  2.23956238e-02,  2.85702534e-02,\n",
              "         8.14967975e-02, -3.42005566e-02]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6V9WM7Gl_2v"
      },
      "source": [
        "## Build Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK1a7HTYl_2w"
      },
      "source": [
        "batch_size = 512\n",
        "\n",
        "train_batches = train_data.shuffle(num_train_examples // 4).batch(batch_size).prefetch(1)\n",
        "validation_batches = validation_data.batch(batch_size).prefetch(1)\n",
        "test_batches = test_data.batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ8uZcqOl_2y"
      },
      "source": [
        "## Build the Model\n",
        "\n",
        "In the code below we will build a Keras `Sequential` model with the following layers:\n",
        "\n",
        "1. The first layer is a TensorFlow Hub layer. This layer uses a pre-trained SavedModel to map a sentence into its embedding vector. The model that we are using ([google/tf2-preview/gnews-swivel-20dim/1](https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1)) splits the sentence into tokens, embeds each token and then combines the embedding. The resulting dimensions are: `(num_examples, embedding_dimension)`.\n",
        "\n",
        "\n",
        "2. This fixed-length output vector is piped through a fully-connected (`Dense`) layer with 16 hidden units.\n",
        "\n",
        "\n",
        "3. The last layer is densely connected with a single output node. Using the `sigmoid` activation function, this value is a float between 0 and 1, representing a probability, or confidence level."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mvUjhw02y9-"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "        hub_layer,\n",
        "        tf.keras.layers.Dense(16, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-kJSvK57S5F"
      },
      "source": [
        "## Train the Model\n",
        "\n",
        "Since this is a binary classification problem and the model outputs a probability (a single-unit layer with a sigmoid activation), we'll use the `binary_crossentropy` loss function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S8wWDol2zBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce8c3b84-47ab-4d8b-f89b-607139083af4"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_batches,\n",
        "                    epochs=2,\n",
        "                    validation_data=validation_batches)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "30/30 [==============================] - 29s 940ms/step - loss: 0.6056 - accuracy: 0.7974 - val_loss: 0.5527 - val_accuracy: 0.8161\n",
            "Epoch 2/2\n",
            "30/30 [==============================] - 28s 934ms/step - loss: 0.5371 - accuracy: 0.8166 - val_loss: 0.4951 - val_accuracy: 0.8232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyORnj-u8F_j"
      },
      "source": [
        "## Evaluate the Model\n",
        "\n",
        "We will now see how well our model performs on the testing set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch6hq1_kl_23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcc55145-8ce9-4902-b0cd-5be3cac75c1b"
      },
      "source": [
        "eval_results = model.evaluate(test_batches, verbose=0)\n",
        "\n",
        "for metric, value in zip(model.metrics_names, eval_results):\n",
        "    print(metric + ': {:.3}'.format(value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.495\n",
            "accuracy: 0.82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_vJ46Gm0jHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87da8744-efe1-4028-f37d-0d39dd39986f"
      },
      "source": [
        "for sample,_ in test_data.take(1):\n",
        "  print(sample.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b\"There are films that make careers. For George Romero, it was NIGHT OF THE LIVING DEAD; for Kevin Smith, CLERKS; for Robert Rodriguez, EL MARIACHI. Add to that list Onur Tukel's absolutely amazing DING-A-LING-LESS. Flawless film-making, and as assured and as professional as any of the aforementioned movies. I haven't laughed this hard since I saw THE FULL MONTY. (And, even then, I don't think I laughed quite this hard... So to speak.) Tukel's talent is considerable: DING-A-LING-LESS is so chock full of double entendres that one would have to sit down with a copy of this script and do a line-by-line examination of it to fully appreciate the, uh, breadth and width of it. Every shot is beautifully composed (a clear sign of a sure-handed director), and the performances all around are solid (there's none of the over-the-top scenery chewing one might've expected from a film like this). DING-A-LING-LESS is a film whose time has come.\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9k-KhH_1Ja_"
      },
      "source": [
        "sample_new = \"There are films that make careers. For George Romero, it was NIGHT OF THE LIVING DEAD; for Kevin Smith, CLERKS; for Robert Rodriguez, EL MARIACHI. Add to that list Onur Tukel's absolutely amazing DING-A-LING-LESS. Flawless film-making, and as assured and as professional as any of the aforementioned movies. I haven't laughed this hard since I saw THE FULL MONTY. (And, even then, I don't think I laughed quite this hard... So to speak.) Tukel's talent is considerable: DING-A-LING-LESS is so chock full of double entendres that one would have to sit down with a copy of this script and do a line-by-line examination of it to fully appreciate the, uh, breadth and width of it. Every shot is beautifully composed (a clear sign of a sure-handed director), and the performances all around are solid (there's none of the over-the-top scenery chewing one might've expected from a film like this). DING-A-LING-LESS is a film whose time has come.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVeByJis1d6j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "891d3bdb-f413-4124-bbf4-ed47059fd285"
      },
      "source": [
        "model.predict([sample_new])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4442073]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwGPItyphqXT"
      },
      "source": [
        "## Save your model\n",
        "\n",
        "To load our trained model into TensorFlow Serving we first need to save it in [SavedModel](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/saved_model) format.  This will create a protobuf file in a well-defined directory hierarchy, and will include a version number.  [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving) allows us to select which version of a model, or \"servable\" we want to use when we make inference requests.  Each version will be exported to a different sub-directory under the given path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w5Rq8SsgWE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f75f22be-98a0-4158-d6a0-ed79e0ba6787"
      },
      "source": [
        "# Fetch the Keras session and save the model\n",
        "# The signature definition is defined by the input and output tensors,\n",
        "# and stored with the default serving key\n",
        "import tempfile, os\n",
        "from tensorflow import keras\n",
        "MODEL_DIR = tempfile.gettempdir()\n",
        "version = 1\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "print('export_path = {}\\n'.format(export_path))\n",
        "if os.path.isdir(export_path):\n",
        "  print('\\nAlready saved a model, cleaning up\\n')\n",
        "  !rm -r {export_path}\n",
        "\n",
        "tf.saved_model.save(\n",
        "    model,\n",
        "    export_path)\n",
        "\n",
        "print('\\nSaved model:')\n",
        "!ls -l {export_path}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "export_path = /tmp/1\n",
            "\n",
            "INFO:tensorflow:Assets written to: /tmp/1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/1/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Saved model:\n",
            "total 8512\n",
            "drwxr-xr-x 2 root root    4096 Dec 20 21:05 assets\n",
            "-rw-r--r-- 1 root root 8706149 Dec 20 21:05 saved_model.pb\n",
            "drwxr-xr-x 2 root root    4096 Dec 20 21:05 variables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM7B_RuDYoIj"
      },
      "source": [
        "## Examine your saved model\n",
        "\n",
        "We'll use the command line utility `saved_model_cli` to look at the [MetaGraphDefs](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/MetaGraphDef) (the models) and [SignatureDefs](../signature_defs) (the methods you can call) in our SavedModel.  See [this discussion of the SavedModel CLI](https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#cli-to-inspect-and-execute-savedmodel) in the TensorFlow Guide."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU4GDF_aYtfQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e8dc765-75ee-4eb8-d228-f7a9b8620603"
      },
      "source": [
        "!saved_model_cli show --dir {export_path} --all"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['keras_layer_input'] tensor_info:\n",
            "        dtype: DT_STRING\n",
            "        shape: (-1)\n",
            "        name: serving_default_keras_layer_input:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_1'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 1)\n",
            "        name: StatefulPartitionedCall_1:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W1220 21:05:32.246644 140106034042752 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "2020-12-20 21:05:33.002083: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-12-20 21:05:33.006822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-20 21:05:33.007389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-12-20 21:05:33.007652: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-12-20 21:05:33.009382: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-12-20 21:05:33.011323: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-12-20 21:05:33.011636: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-12-20 21:05:33.022809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-12-20 21:05:33.032384: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-12-20 21:05:33.047535: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-12-20 21:05:33.047654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-20 21:05:33.048199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-20 21:05:33.048744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2020-12-20 21:05:33.102908: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-12-20 21:05:33.103115: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556615e29640 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-12-20 21:05:33.103143: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-12-20 21:05:33.207349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-20 21:05:33.207985: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556615e29800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-12-20 21:05:33.208015: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-12-20 21:05:33.208193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-20 21:05:33.208849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-12-20 21:05:33.208910: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-12-20 21:05:33.208933: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-12-20 21:05:33.208950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-12-20 21:05:33.208966: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-12-20 21:05:33.208982: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-12-20 21:05:33.209000: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-12-20 21:05:33.209017: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-12-20 21:05:33.209083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-20 21:05:33.209787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-20 21:05:33.210431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2020-12-20 21:05:33.214055: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-12-20 21:05:33.215359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-12-20 21:05:33.215391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
            "2020-12-20 21:05:33.215402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
            "2020-12-20 21:05:33.217406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-20 21:05:33.217951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-20 21:05:33.218641: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-12-20 21:05:33.218697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12008 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "\n",
            "Defined Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None,), dtype=tf.string, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          keras_layer_input: TensorSpec(shape=(None,), dtype=tf.string, name=u'keras_layer_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          keras_layer_input: TensorSpec(shape=(None,), dtype=tf.string, name=u'keras_layer_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None,), dtype=tf.string, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          keras_layer_input: TensorSpec(shape=(None,), dtype=tf.string, name=u'keras_layer_input')\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None,), dtype=tf.string, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None,), dtype=tf.string, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          keras_layer_input: TensorSpec(shape=(None,), dtype=tf.string, name=u'keras_layer_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          keras_layer_input: TensorSpec(shape=(None,), dtype=tf.string, name=u'keras_layer_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSPWuegUb7Eo"
      },
      "source": [
        "That tells us a lot about our model!  In this case we just trained our model, so we already know the inputs and outputs, but if we didn't this would be important information.  It doesn't tell us everything, like the fact that this is grayscale image data for example, but it's a great start."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBgsyhytS6KD"
      },
      "source": [
        "## Serve your model with TensorFlow Serving\n",
        "\n",
        "### Add TensorFlow Serving distribution URI as a package source:\n",
        "\n",
        "We're preparing to install TensorFlow Serving using [Aptitude](https://wiki.debian.org/Aptitude) since this Colab runs in a Debian environment.  We'll add the `tensorflow-model-server` package to the list of packages that Aptitude knows about.  Note that we're running as root.\n",
        "\n",
        "Note: This example is running TensorFlow Serving natively, but [you can also run it in a Docker container](https://www.tensorflow.org/tfx/serving/docker), which is one of the easiest ways to get started using TensorFlow Serving."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwg1JKaGXWAg"
      },
      "source": [
        "## Make a request to your model in TensorFlow Serving\n",
        "\n",
        "First, let's take a look at a random example from our test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWg9X2QHlbGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "677ac881-35e0-4149-d986-b0bfaa3b3e21"
      },
      "source": [
        "# This is the same as you would do from your command line, but without the [arch=amd64], and no sudo\n",
        "# You would instead do:\n",
        "# echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "# curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -\n",
        "\n",
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2943  100  2943    0     0   136k      0 --:--:-- --:--:-- --:--:--  143k\n",
            "OK\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:3 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,012 B]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Get:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release [564 B]\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:11 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [40.7 kB]\n",
            "Get:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release.gpg [833 B]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:14 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [346 B]\n",
            "Get:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:16 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [340 B]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,372 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [15.3 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,816 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [237 kB]\n",
            "Ign:22 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:22 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [506 kB]\n",
            "Get:23 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages [66.1 kB]\n",
            "Get:24 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,700 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,244 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [53.8 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,136 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [266 kB]\n",
            "Get:29 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [870 kB]\n",
            "Get:30 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [46.5 kB]\n",
            "Fetched 11.7 MB in 3s (4,159 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "59 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1ZVp_VOU7Wu"
      },
      "source": [
        "### Install TensorFlow Serving\n",
        "\n",
        "This is all you need - one command line!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygwa9AgRloYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad778e8a-290f-44fe-c888-bb6a4c1ab2f4"
      },
      "source": [
        "!apt-get install tensorflow-model-server"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tensorflow-model-server\n",
            "0 upgraded, 1 newly installed, 0 to remove and 59 not upgraded.\n",
            "Need to get 223 MB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.4.0 [223 MB]\n",
            "Fetched 223 MB in 3s (86.7 MB/s)\n",
            "Selecting previously unselected package tensorflow-model-server.\n",
            "(Reading database ... 144865 files and directories currently installed.)\n",
            "Preparing to unpack .../tensorflow-model-server_2.4.0_all.deb ...\n",
            "Unpacking tensorflow-model-server (2.4.0) ...\n",
            "Setting up tensorflow-model-server (2.4.0) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5NrYdQeVm52"
      },
      "source": [
        "### Start running TensorFlow Serving\n",
        "\n",
        "This is where we start running TensorFlow Serving and load our model.  After it loads we can start making inference requests using REST.  There are some important parameters:\n",
        "\n",
        "* `rest_api_port`: The port that you'll use for REST requests.\n",
        "* `model_name`: You'll use this in the URL of REST requests.  It can be anything.\n",
        "* `model_base_path`: This is the path to the directory where you've saved your model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUgp3vUdU5GS"
      },
      "source": [
        "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJDhHNJVnaLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e584bbc-f213-4190-ffd9-52e1e7c85625"
      },
      "source": [
        "%%bash --bg \n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port=8501 \\\n",
        "  --model_name=model \\\n",
        "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting job # 0 in a separate thread.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxbeiOCUUs2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5812eeb-ea13-4ff0-9b42-3820d6028cb3"
      },
      "source": [
        "!tail server.log"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-20 21:05:48.985547: I tensorflow_serving/model_servers/server.cc:88] Building single TensorFlow model file config:  model_name: model model_base_path: /tmp\n",
            "2020-12-20 21:05:48.985814: I tensorflow_serving/model_servers/server_core.cc:464] Adding/updating models.\n",
            "2020-12-20 21:05:48.985848: I tensorflow_serving/model_servers/server_core.cc:587]  (Re-)adding model: model\n",
            "2020-12-20 21:05:48.988055: I tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: model version: 1}\n",
            "2020-12-20 21:05:48.988090: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: model version: 1}\n",
            "2020-12-20 21:05:48.988107: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: model version: 1}\n",
            "2020-12-20 21:05:48.988151: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: /tmp/1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dsD7KQG1m-R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b8553f8-99b1-4ee9-f62c-310e4d2c7f5e"
      },
      "source": [
        "import json, requests\n",
        "sample_new = \"There are films that make careers. For George Romero, it was NIGHT OF THE LIVING DEAD; for Kevin Smith, CLERKS; for Robert Rodriguez, EL MARIACHI. Add to that list Onur Tukel's absolutely amazing DING-A-LING-LESS. Flawless film-making, and as assured and as professional as any of the aforementioned movies. I haven't laughed this hard since I saw THE FULL MONTY. (And, even then, I don't think I laughed quite this hard... So to speak.) Tukel's talent is considerable: DING-A-LING-LESS is so chock full of double entendres that one would have to sit down with a copy of this script and do a line-by-line examination of it to fully appreciate the, uh, breadth and width of it. Every shot is beautifully composed (a clear sign of a sure-handed director), and the performances all around are solid (there's none of the over-the-top scenery chewing one might've expected from a film like this). DING-A-LING-LESS is a film whose time has come.\"\n",
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": [sample_new]})\n",
        "print('Data: {} ... {}'.format(data[:50], data[len(data)-52:]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data: {\"signature_name\": \"serving_default\", \"instances\": ... . DING-A-LING-LESS is a film whose time has come.\"]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iUdsaDe7W_b"
      },
      "source": [
        "!pip install -q requests\n",
        "\n",
        "import requests\n",
        "headers = {\"content-type\": \"application/json\"}\n",
        "json_response = requests.post('http://localhost:8501/v1/models/model:predict', data=data, headers=headers)\n",
        "predictions = json.loads(json_response.text)['predictions']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbsaTEJL8vKP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "520b43d4-5c50-45aa-ff4f-dda4a1676bb6"
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.444207281]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wov2BazjQoxK"
      },
      "source": [
        "# Trick to Run On Google-Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YUnpG6uZOrT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c26c5c45-ca57-4111-dcc0-89871f1f3626"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-20 21:05:53--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.196.227.142, 52.87.143.234, 34.232.108.170, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.196.227.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  43.2MB/s    in 0.3s    \n",
            "\n",
            "2020-12-20 21:05:54 (43.2 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIK3QUI7ZRtQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c3df23b-38e2-4d6d-a528-7fe2eebf5cec"
      },
      "source": [
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zn8HNhXaLlZ"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 8501 &')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGmQf6WUaPMC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0402f3b1-3da9-4418-9126-a8ea5cff3aa8"
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "IndexError: list index out of range\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfXBv5tR2RmG",
        "outputId": "62ad6b9f-77ee-4032-8a34-39b0d3c04624"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "command = \"curl -s http://localhost:4040/api/tunnels | python3 -c  \\\"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\\\"\"\n",
        "subprocess = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n",
        "subprocess_return = subprocess.stdout.read().decode().replace(\"\\n\",\"\")\n",
        "print(subprocess_return)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://c5b8f1683cc0.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of1dwaAN_Q2X"
      },
      "source": [
        "Now you can use the code below to call API form anywhere just copy the code and \"subprocess_return\" variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hdq0GyEN4Gy2",
        "outputId": "8b4e5265-336b-4baa-81d6-5123b29aa885"
      },
      "source": [
        "print(f\"Api is hosted on {subprocess_return}\")\n",
        "\n",
        "sample_new = \"There are films that make careers. For George Romero, it was NIGHT OF THE LIVING DEAD; for Kevin Smith, CLERKS; for Robert Rodriguez, EL MARIACHI. Add to that list Onur Tukel's absolutely amazing DING-A-LING-LESS. Flawless film-making, and as assured and as professional as any of the aforementioned movies. I haven't laughed this hard since I saw THE FULL MONTY. (And, even then, I don't think I laughed quite this hard... So to speak.) Tukel's talent is considerable: DING-A-LING-LESS is so chock full of double entendres that one would have to sit down with a copy of this script and do a line-by-line examination of it to fully appreciate the, uh, breadth and width of it. Every shot is beautifully composed (a clear sign of a sure-handed director), and the performances all around are solid (there's none of the over-the-top scenery chewing one might've expected from a film like this). DING-A-LING-LESS is a film whose time has come.\"\n",
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": [sample_new]})\n",
        "print('Data: {} ... {}'.format(data[:50], data[len(data)-52:]))\n",
        "\n",
        "headers = {\"content-type\": \"application/json\"}\n",
        "json_response = requests.post(f'{subprocess_return}/v1/models/model/versions/1:predict', data=data, headers=headers)\n",
        "predictions = json.loads(json_response.text)['predictions']\n",
        "print(f\"Output, {predictions}\") # threshold on 0.5 to get the class; if output >= 0.5 then class 1 else class 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Api is hosted on https://c5b8f1683cc0.ngrok.io\n",
            "Data: {\"signature_name\": \"serving_default\", \"instances\": ... . DING-A-LING-LESS is a film whose time has come.\"]}\n",
            "Output, [[0.444207281]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}